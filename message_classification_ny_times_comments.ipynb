{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>timespeople</th>\n",
       "      <th>trusted</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1520043821</td>\n",
       "      <td>5a974697410cf7000162e8a4</td>\n",
       "      <td>1207</td>\n",
       "      <td>If the choice is between mining for bitcoin - ...</td>\n",
       "      <td>26188943.0</td>\n",
       "      <td>26188943.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1520029445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1520043821</td>\n",
       "      <td>Steve</td>\n",
       "      <td>46903103.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1520043790</td>\n",
       "      <td>5a974697410cf7000162e8a4</td>\n",
       "      <td>1207</td>\n",
       "      <td>&lt;br/&gt;To me, Bitcoin (et al) appears to be an e...</td>\n",
       "      <td>26189292.0</td>\n",
       "      <td>26189292.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1520031265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1520043790</td>\n",
       "      <td>MyOpinion</td>\n",
       "      <td>82778.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1520043789</td>\n",
       "      <td>5a974697410cf7000162e8a4</td>\n",
       "      <td>1207</td>\n",
       "      <td>Bitcoin is a pyramid scheme backed by nothing ...</td>\n",
       "      <td>26189645.0</td>\n",
       "      <td>26189645.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1520033172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1520043789</td>\n",
       "      <td>Bert Gold</td>\n",
       "      <td>3013548.0</td>\n",
       "      <td>Frederick, Maryland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1520043788</td>\n",
       "      <td>5a974697410cf7000162e8a4</td>\n",
       "      <td>1207</td>\n",
       "      <td>What does it cost in energy to dig up and refi...</td>\n",
       "      <td>26189102.0</td>\n",
       "      <td>26189102.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1520030291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1520043788</td>\n",
       "      <td>James Demers</td>\n",
       "      <td>70245222.0</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1520043787</td>\n",
       "      <td>5a974697410cf7000162e8a4</td>\n",
       "      <td>1207</td>\n",
       "      <td>You forgot to mention stock buybacks.</td>\n",
       "      <td>26189683.0</td>\n",
       "      <td>26189683.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1520033404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1520043787</td>\n",
       "      <td>Bill</td>\n",
       "      <td>66424344.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approveDate                 articleID  articleWordCount  \\\n",
       "0   1520043821  5a974697410cf7000162e8a4              1207   \n",
       "1   1520043790  5a974697410cf7000162e8a4              1207   \n",
       "2   1520043789  5a974697410cf7000162e8a4              1207   \n",
       "3   1520043788  5a974697410cf7000162e8a4              1207   \n",
       "4   1520043787  5a974697410cf7000162e8a4              1207   \n",
       "\n",
       "                                         commentBody   commentID  \\\n",
       "0  If the choice is between mining for bitcoin - ...  26188943.0   \n",
       "1  <br/>To me, Bitcoin (et al) appears to be an e...  26189292.0   \n",
       "2  Bitcoin is a pyramid scheme backed by nothing ...  26189645.0   \n",
       "3  What does it cost in energy to dig up and refi...  26189102.0   \n",
       "4             You forgot to mention stock buybacks.   26189683.0   \n",
       "\n",
       "   commentSequence commentTitle commentType  createDate  depth  ...    status  \\\n",
       "0       26188943.0        <br/>     comment  1520029445    1.0  ...  approved   \n",
       "1       26189292.0        <br/>     comment  1520031265    1.0  ...  approved   \n",
       "2       26189645.0        <br/>     comment  1520033172    1.0  ...  approved   \n",
       "3       26189102.0        <br/>     comment  1520030291    1.0  ...  approved   \n",
       "4       26189683.0        <br/>     comment  1520033404    1.0  ...  approved   \n",
       "\n",
       "   timespeople trusted  updateDate  userDisplayName      userID  \\\n",
       "0            1       0  1520043821            Steve  46903103.0   \n",
       "1            1       0  1520043790        MyOpinion     82778.0   \n",
       "2            1       0  1520043789        Bert Gold   3013548.0   \n",
       "3            1       0  1520043788     James Demers  70245222.0   \n",
       "4            1       0  1520043787             Bill  66424344.0   \n",
       "\n",
       "          userLocation  userTitle  userURL  typeOfMaterial  \n",
       "0              Florida        NaN      NaN            News  \n",
       "1                  NYC        NaN      NaN            News  \n",
       "2  Frederick, Maryland        NaN      NaN            News  \n",
       "3             Brooklyn        NaN      NaN            News  \n",
       "4           California        NaN      NaN            News  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read data\n",
    "reviews_df = pd.read_csv(\"/Users/liorlavi/Downloads/nyt-comments/CommentsMarch2018.csv\", nrows=10000)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step consists in cleaning the text data with various operations:\n",
    "# return the wordnet object value corresponding to the POS tag\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n",
      "[nltk_data]     failed: unable to get local issuer certificate\n",
      "[nltk_data]     (_ssl.c:1056)>\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "    \n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "# clean text data\n",
    "reviews_df[\"commentBody_clean\"] = reviews_df[\"commentBody\"].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean textual data, we call our custom â€˜clean_textâ€™ function that performs several transformations:\n",
    "#lower the text\n",
    "#tokenize the text (split the text into words) and remove the punctuation\n",
    "#remove useless words that contain numbers\n",
    "#remove useless stop words like â€˜theâ€™, â€˜aâ€™ ,â€™thisâ€™ etc.\n",
    "#Part-Of-Speech (POS) tagging: assign a tag to every word to define if it corresponds to a noun, a verb etc. using the WordNet lexical database\n",
    "#lemmatize the text: transform every word into their root form (e.g. rooms -> room, slept -> sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading vader_lexicon: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1056)>\n"
     ]
    }
   ],
   "source": [
    "# add sentiment anaylsis columns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "reviews_df[\"sentiments\"] = reviews_df[\"commentBody\"].apply(lambda x: sid.polarity_scores(x))\n",
    "reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first start by adding sentiment analysis features because we can guess that customers reviews are highly linked to how they felt about their stay at the hotel. \n",
    "# We use Vader, which is a part of the NLTK module designed for sentiment analysis. \n",
    "# Vader uses a lexicon of words to find which ones are positives or negatives. \n",
    "# It also takes into account the context of the sentences to determine the sentiment scores. \n",
    "# For each text, Vader returns 4 values:\n",
    "#a neutrality score\n",
    "#a positivity score\n",
    "#a negativity score\n",
    "#an overall score that summarizes the previous scores\n",
    "#We will integrate those 4 values as features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of characters column\n",
    "reviews_df[\"nb_chars\"] = reviews_df[\"commentBody_clean\"].apply(lambda x: len(x))\n",
    "\n",
    "# add number of words column\n",
    "reviews_df[\"nb_words\"] = reviews_df[\"commentBody_clean\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we add some simple metrics for every text:\n",
    "#number of characters in the text\n",
    "#number of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create doc2vec vector columns\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews_df[\"commentBody_clean\"].apply(lambda x: x.split(\" \")))]\n",
    "\n",
    "# train a Doc2Vec model with our text data\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "# transform each document into a vector data\n",
    "doc2vec_df = reviews_df[\"commentBody_clean\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
    "reviews_df = pd.concat([reviews_df, doc2vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step consist in extracting vector representations for every review. \n",
    "# The module Gensim creates a numerical vector representation of every word in the corpus by using the contexts in which they appear (Word2Vec). This is performed using shallow neural networks. Whatâ€™s interesting is that similar words will have similar representation vectors.\n",
    "# Each text can also be transformed into numerical vectors using the word vectors (Doc2Vec). \n",
    "# Same texts will also have similar representations and that is why we can use those vectors as training features.\n",
    "# We first have to train a Doc2Vec model by feeding in our text data. By applying this model on our reviews, \n",
    "# we can get those representation vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tf-idfs columns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df = 10)\n",
    "tfidf_result = tfidf.fit_transform(reviews_df[\"commentBody_clean\"]).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "tfidf_df.index = reviews_df.index\n",
    "reviews_df = pd.concat([reviews_df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we add the TF-IDF (Term Frequency â€” Inverse Document Frequency) values for every word and every document.\n",
    "# But why not simply counting how many times each word appears in every document? \n",
    "# The problem with this method is that it doesnâ€™t take into account the relative importance of words in the texts. \n",
    "# A word that appears in almost every text would not likely bring useful information for analysis. \n",
    "# On the contrary, rare words may have a lot more of meanings.\n",
    "# The TF-IDF metric solves this problem:\n",
    "# TF computes the classic number of times the word appears in the text\n",
    "# IDF computes the relative importance of this word which depends on how many texts the word can be found\n",
    "# We add TF-IDF columns for every word that appear in at least 10 different texts to filter some of them and reduce the size of the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>...</th>\n",
       "      <th>word_yet</th>\n",
       "      <th>word_york</th>\n",
       "      <th>word_yorker</th>\n",
       "      <th>word_yorkers</th>\n",
       "      <th>word_you</th>\n",
       "      <th>word_young</th>\n",
       "      <th>word_your</th>\n",
       "      <th>word_youth</th>\n",
       "      <th>word_zero</th>\n",
       "      <th>word_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>1520003388</td>\n",
       "      <td>5a97cf5d410cf7000162e9b7</td>\n",
       "      <td>1391</td>\n",
       "      <td>Louvre: â‚¬15&lt;br/&gt;Brooklyn Mus: $16&lt;br/&gt;Philadel...</td>\n",
       "      <td>26174956.0</td>\n",
       "      <td>26174956.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519957142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>1519936219</td>\n",
       "      <td>5a981947410cf7000162eaa2</td>\n",
       "      <td>1556</td>\n",
       "      <td>The most elastic component of any economic sys...</td>\n",
       "      <td>26171145.0</td>\n",
       "      <td>26171145.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519936213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1519961971</td>\n",
       "      <td>5a984b45410cf7000162eb58</td>\n",
       "      <td>1115</td>\n",
       "      <td>Maybe Melania sees a threat:  Hicks may be her...</td>\n",
       "      <td>26174921.0</td>\n",
       "      <td>26174921.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519956912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>1519995106</td>\n",
       "      <td>5a98961c410cf7000162ec46</td>\n",
       "      <td>1217</td>\n",
       "      <td>So much for not being afraid of the NRA. Such ...</td>\n",
       "      <td>26177961.0</td>\n",
       "      <td>26177961.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519994617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>1519939512</td>\n",
       "      <td>5a97d9ca410cf7000162e9da</td>\n",
       "      <td>896</td>\n",
       "      <td>How completely absurd (and trite) to categoriz...</td>\n",
       "      <td>26168836.0</td>\n",
       "      <td>26168836.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519927003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>1519969015</td>\n",
       "      <td>5a97eb6d410cf7000162ea14</td>\n",
       "      <td>2102</td>\n",
       "      <td>I read this book about 10 times as a kid. I re...</td>\n",
       "      <td>26176271.0</td>\n",
       "      <td>26176271.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519969011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>1519957496</td>\n",
       "      <td>5a98465d410cf7000162eb49</td>\n",
       "      <td>1711</td>\n",
       "      <td>I graduated college in 2009 and I never worrie...</td>\n",
       "      <td>26173574.0</td>\n",
       "      <td>26173574.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519948105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8602</th>\n",
       "      <td>1520003933</td>\n",
       "      <td>5a989bd9410cf7000162ec56</td>\n",
       "      <td>1383</td>\n",
       "      <td>\"Lawmakers need to harden some of these norms ...</td>\n",
       "      <td>26177170.0</td>\n",
       "      <td>26177170.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519988269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>1520095994</td>\n",
       "      <td>5a98a82e410cf7000162ec77</td>\n",
       "      <td>1764</td>\n",
       "      <td>These are the clear signs of a crumbling democ...</td>\n",
       "      <td>26192761.0</td>\n",
       "      <td>26192761.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1520080914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>1519934707</td>\n",
       "      <td>5a97ff69410cf7000162ea4a</td>\n",
       "      <td>1510</td>\n",
       "      <td>Washington wants absolute global military supr...</td>\n",
       "      <td>26170092.0</td>\n",
       "      <td>26170092.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1519931793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 4557 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      approveDate                 articleID  articleWordCount  \\\n",
       "960    1520003388  5a97cf5d410cf7000162e9b7              1391   \n",
       "4271   1519936219  5a981947410cf7000162eaa2              1556   \n",
       "5687   1519961971  5a984b45410cf7000162eb58              1115   \n",
       "8347   1519995106  5a98961c410cf7000162ec46              1217   \n",
       "2244   1519939512  5a97d9ca410cf7000162e9da               896   \n",
       "2810   1519969015  5a97eb6d410cf7000162ea14              2102   \n",
       "5281   1519957496  5a98465d410cf7000162eb49              1711   \n",
       "8602   1520003933  5a989bd9410cf7000162ec56              1383   \n",
       "8790   1520095994  5a98a82e410cf7000162ec77              1764   \n",
       "3511   1519934707  5a97ff69410cf7000162ea4a              1510   \n",
       "\n",
       "                                            commentBody   commentID  \\\n",
       "960   Louvre: â‚¬15<br/>Brooklyn Mus: $16<br/>Philadel...  26174956.0   \n",
       "4271  The most elastic component of any economic sys...  26171145.0   \n",
       "5687  Maybe Melania sees a threat:  Hicks may be her...  26174921.0   \n",
       "8347  So much for not being afraid of the NRA. Such ...  26177961.0   \n",
       "2244  How completely absurd (and trite) to categoriz...  26168836.0   \n",
       "2810  I read this book about 10 times as a kid. I re...  26176271.0   \n",
       "5281  I graduated college in 2009 and I never worrie...  26173574.0   \n",
       "8602  \"Lawmakers need to harden some of these norms ...  26177170.0   \n",
       "8790  These are the clear signs of a crumbling democ...  26192761.0   \n",
       "3511  Washington wants absolute global military supr...  26170092.0   \n",
       "\n",
       "      commentSequence commentTitle commentType  createDate  depth  ...  \\\n",
       "960        26174956.0        <br/>     comment  1519957142    1.0  ...   \n",
       "4271       26171145.0        <br/>     comment  1519936213    1.0  ...   \n",
       "5687       26174921.0        <br/>     comment  1519956912    1.0  ...   \n",
       "8347       26177961.0        <br/>     comment  1519994617    1.0  ...   \n",
       "2244       26168836.0        <br/>     comment  1519927003    1.0  ...   \n",
       "2810       26176271.0        <br/>     comment  1519969011    1.0  ...   \n",
       "5281       26173574.0        <br/>     comment  1519948105    1.0  ...   \n",
       "8602       26177170.0        <br/>     comment  1519988269    1.0  ...   \n",
       "8790       26192761.0        <br/>     comment  1520080914    1.0  ...   \n",
       "3511       26170092.0        <br/>     comment  1519931793    1.0  ...   \n",
       "\n",
       "      word_yet  word_york word_yorker  word_yorkers  word_you  word_young  \\\n",
       "960   0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "4271  0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "5687  0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "8347  0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "2244  0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "2810  0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "5281  0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "8602  0.156482        0.0         0.0           0.0       0.0         0.0   \n",
       "8790  0.089708        0.0         0.0           0.0       0.0         0.0   \n",
       "3511  0.000000        0.0         0.0           0.0       0.0         0.0   \n",
       "\n",
       "     word_your  word_youth  word_zero  word_zone  \n",
       "960        0.0         0.0        0.0        0.0  \n",
       "4271       0.0         0.0        0.0        0.0  \n",
       "5687       0.0         0.0        0.0        0.0  \n",
       "8347       0.0         0.0        0.0        0.0  \n",
       "2244       0.0         0.0        0.0        0.0  \n",
       "2810       0.0         0.0        0.0        0.0  \n",
       "5281       0.0         0.0        0.0        0.0  \n",
       "8602       0.0         0.0        0.0        0.0  \n",
       "8790       0.0         0.0        0.0        0.0  \n",
       "3511       0.0         0.0        0.0        0.0  \n",
       "\n",
       "[10 rows x 4557 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def make_ngram(df, col, N):\n",
    "    return reduce(\n",
    "        list.__add__, \n",
    "        (list(\"_\".join(j) for j in nltk.ngrams(i.replace('â†µ', ' ').replace('|','').replace(':', '').split(), N))\n",
    "        for i in df[col].values), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = pd.Series(make_ngram(reviews_df, \"commentBody_clean\", 2))\n",
    "trigram = pd.Series(make_ngram(reviews_df, \"commentBody_clean\", 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(10,8), sharex=True)\n",
    "pd.value_counts(bigram).head(20)[::-1].plot.barh(ax=ax1, rot=0)\n",
    "pd.value_counts(trigram).head(20)[::-1].plot.barh(ax=ax2, rot=0)\n",
    "ax1.set_title('Bigram')\n",
    "ax2.set_title('Trigram')\n",
    "ax2.set_xlabel(\"N-gram counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud function\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud(data, title = 'Post-booking messages Word Cloud'):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        \n",
    "        max_words = 100,\n",
    "        max_font_size = 45, \n",
    "        scale = 25,\n",
    "        random_state = 1\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize = (20, 10))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 0.9)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "    \n",
    "    # print wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(reviews_df[\"commentBody_clean\"])\n",
    "show_wordcloud(bigram, title=\"bigram\")\n",
    "show_wordcloud(trigram, title=\"Trigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the words are indeed related to the hotels: room, staff, breakfast, etc. \n",
    "# Some words are more related to the customer experience with the hotel stay: perfect, loved, expensive, dislike, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest positive sentiment reviews (with more than 5 words)\n",
    "reviews_df[reviews_df[\"nb_words\"] >= 5].sort_values(\"pos\", ascending = False)[[\"commentBody_clean\", \"pos\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest negative sentiment reviews (with more than 5 words)\n",
    "reviews_df[reviews_df[\"nb_words\"] >= 5].sort_values(\"neg\", ascending = False)[[\"commentBody\", \"neg\"]].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some errors can be found among the most negative reviews: \n",
    "# Vader sometimes interpret â€˜noâ€™ or â€˜nothingâ€™ as negative words whereas they are sometimes used to say that there were no problems with the hotel. \n",
    "# Fortunately, most of the reviews are indeed bad ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
